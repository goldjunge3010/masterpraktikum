{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcl2FDybYN0RqbNUXjJZju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goldjunge3010/masterpraktikum/blob/main/Demo_RetentionTimeReport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation and imports\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "73msxoAkwbiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GZxoVSldvqaQ"
      },
      "outputs": [],
      "source": [
        "# install necessary packages\n",
        "!python -m pip install -q dlomix==0.0.4\n",
        "!python -m pip install -q wandb\n",
        "\n",
        "# import necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from wandb.keras import WandbMetricsLogger\n",
        "import wandb.apis.reports as wr\n",
        "\n",
        "import dlomix\n",
        "from dlomix import constants, data, eval, layers, models, pipelines, reports, utils\n",
        "from dlomix.data import RetentionTimeDataset\n",
        "from dlomix.models import PrositRetentionTimePredictor\n",
        "from dlomix.models import RetentionTimePredictor\n",
        "from dlomix.eval import TimeDeltaMetric\n",
        "\n",
        "class Report():\n",
        "\n",
        "  def __init__(self, project:str, title: str, description: str, dataset: RetentionTimeDataset):\n",
        "    self.entity = wandb.apis.PublicApi().default_entity\n",
        "    self.project = project\n",
        "    self.title = title\n",
        "    self.description = description\n",
        "    self.api = wandb.Api()\n",
        "    self.dataset = dataset\n",
        "    self.table_key_len = \"\"\n",
        "    self.table_key_rt = \"\"\n",
        "    self.model_info = []\n",
        "\n",
        "  def create_report(self, add_config_section = True, add_data_section = True, add_train_section = True, add_val_section = True, add_train_val_section = True, add_model_section = True):\n",
        "    report = wr.Report(\n",
        "        project = self.project,\n",
        "        title = self.title,\n",
        "        description = self.description\n",
        "    )\n",
        "\n",
        "    report.blocks = [\n",
        "        wr.TableOfContents()\n",
        "    ]\n",
        "    if add_model_section:\n",
        "      report.blocks += self.model_section()\n",
        "    if add_config_section:\n",
        "      report.blocks += self.config_section()\n",
        "    if add_data_section:\n",
        "      report.blocks += self.data_section()\n",
        "    if add_train_section:\n",
        "      report.blocks += self.train_section()\n",
        "    if add_val_section:\n",
        "      report.blocks += self.val_section()\n",
        "    if add_train_val_section:\n",
        "      report.blocks += self.train_val_section()\n",
        "\n",
        "\n",
        "    report.save()\n",
        "\n",
        "\n",
        "\n",
        "  # get metrics of last run in project or from specified run_id\n",
        "  def get_metrics(self, run_id = None):\n",
        "    if run_id:\n",
        "      # run is specified by <entity>/<project>/<run_id>\n",
        "      run = self.api.run(path = f\"{self.entity}/{self.project}/{run_id}\")\n",
        "      metrics_dataframe = run.history()\n",
        "      return metrics_dataframe\n",
        "    else:\n",
        "      # get metrics of latest run\n",
        "      # api.runs seems to have a delay\n",
        "      runs = self.api.runs(path = f\"{self.entity}/{self.project}\")\n",
        "      run = runs[0]\n",
        "      metrics_dataframe = run.history()\n",
        "      return metrics_dataframe\n",
        "\n",
        "  # get metric names split into train/val, train is further split into batch/epoch\n",
        "  def get_metrics_names(self):\n",
        "    metrics = self.get_metrics()\n",
        "    # filter strings from list that are not starting with \"_\" and do not contain \"val\"\n",
        "    pre_filter = [string for string in metrics if not string.startswith(\"_\")]\n",
        "    batch_train_metrics_names = [string for string in pre_filter if (\"val\" not in string.lower()) & (\"epoch\" not in string.lower()) & (\"table\" not in string.lower())]\n",
        "    epoch_train_metrics_names = [string for string in pre_filter if (\"val\" not in string.lower()) & (\"batch\" not in string.lower()) & (\"table\" not in string.lower())]\n",
        "    # filter strings from list that contain \"val\"\n",
        "    epoch_val_metrics_names = list(filter(lambda x: \"val\" in x.lower(), metrics))\n",
        "    # filter strings from train metrics that are 'epoch/learning_rate' and 'epoch/epoch'\n",
        "    strings_to_filter = ['epoch/learning_rate', 'epoch/epoch', 'batch/learning_rate', 'batch/batch_step']\n",
        "    batch_train_metrics_names = [string for string in batch_train_metrics_names if string not in strings_to_filter]\n",
        "    epoch_train_metrics_names = [string for string in epoch_train_metrics_names if string not in strings_to_filter]\n",
        "    batch_train_metrics_names.sort()\n",
        "    epoch_train_metrics_names.sort()\n",
        "    return batch_train_metrics_names, epoch_train_metrics_names, epoch_val_metrics_names\n",
        "\n",
        "  def get_train_val_metrics_names(self):\n",
        "    _, epoch_train_metrics_names, epoch_val_metrics_names = self.get_metrics_names()\n",
        "    epoch_train_metrics_names.sort()\n",
        "    epoch_val_metrics_names.sort()\n",
        "    return list(zip(epoch_train_metrics_names, epoch_val_metrics_names))\n",
        "\n",
        "\n",
        "  def config_section(self):\n",
        "    config_block = [\n",
        "        wr.H1(text = \"Config\"),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels=[\n",
        "            wr.RunComparer(layout = {'w': 24})\n",
        "          ],\n",
        "        ),\n",
        "        wr.HorizontalRule(),\n",
        "    ]\n",
        "    return config_block\n",
        "\n",
        "  def data_section(self):\n",
        "    data_block = [\n",
        "        wr.H1(text = \"Data\"),\n",
        "        wr.P(\"The following section is showing a simple explorative data analysis of the used dataset. The first histogram shows the distribution of peptide lengths in the data set, while the second histogram shows the distribution of indexed retention times.\"),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels=[\n",
        "            wr.CustomChart(\n",
        "              query = {'summaryTable': {\"tableKey\" : self.table_key_len}},\n",
        "              chart_name='master_praktikum/hist_pep_len',\n",
        "              chart_fields={'value': self.dataset.sequence_col}\n",
        "            ),\n",
        "            wr.CustomChart(\n",
        "              query = {'summaryTable': {\"tableKey\" : self.table_key_rt}},\n",
        "              chart_name='master_praktikum/hist_ret_time',\n",
        "              chart_fields={'value': self.dataset.target_col}\n",
        "            )\n",
        "          ]\n",
        "        ),\n",
        "        wr.HorizontalRule(),\n",
        "    ]\n",
        "    return data_block\n",
        "\n",
        "  def train_section(self):\n",
        "    batch_train_metrics_names, epoch_train_metrics_names, _ = self.get_metrics_names()\n",
        "    panel_list_batch = []\n",
        "    panel_list_epoch = []\n",
        "    for name in batch_train_metrics_names:\n",
        "      panel_list_batch.append(wr.LinePlot(x='Step', y=[name]))\n",
        "    for name in epoch_train_metrics_names:\n",
        "      panel_list_epoch.append(wr.LinePlot(x='Step', y=[name]))\n",
        "    train_block = [\n",
        "        wr.H1(text = \"Training metrics\"),\n",
        "        wr.P(\"The following section shows the different metrics that were used to track the training. All used metrics are added by default. The first subsection shows the metrics per epoch, whereas the second subsection show the metrics per batch.\"),\n",
        "        wr.H2(text = \"per batch\"),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels = panel_list_batch\n",
        "        ),\n",
        "        wr.H2(text = \"per epoch\"),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels = panel_list_epoch\n",
        "        ),\n",
        "        wr.HorizontalRule(),\n",
        "    ]\n",
        "    return train_block\n",
        "\n",
        "  def val_section(self):\n",
        "    _, _, epoch_val_metrics_names = self.get_metrics_names()\n",
        "    panel_list_epoch = []\n",
        "    for name in epoch_val_metrics_names:\n",
        "      panel_list_epoch.append(wr.LinePlot(x='Step', y=[name]))\n",
        "    val_block = [\n",
        "        wr.H1(text = \"Validation metrics\"),\n",
        "        wr.P(\"The following section shows the different metrics that were used to track the validation. All used metrics are added by default. The metrics are shown per epoch.\"),\n",
        "        wr.H2(text = \"per epoch\"),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels = panel_list_epoch\n",
        "        ),\n",
        "        wr.HorizontalRule(),\n",
        "    ]\n",
        "    return val_block\n",
        "\n",
        "  def train_val_section(self):\n",
        "    train_val_metrics_names = self.get_train_val_metrics_names()\n",
        "    panel_list_epoch = []\n",
        "    for name in train_val_metrics_names:\n",
        "      panel_list_epoch.append(wr.LinePlot(x='Step', y=list(name)))\n",
        "    train_val_block = [\n",
        "        wr.H1(text = \"Train - Validation metrics\"),\n",
        "        wr.P(\"The following section shows the training metrics in comparision with the validation metrics. All used metrics are added by default. The metrics are shown per epoch.\"),\n",
        "        wr.H2(text = \"per epoch\"),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels = panel_list_epoch\n",
        "        ),\n",
        "        wr.HorizontalRule(),\n",
        "    ]\n",
        "    return train_val_block\n",
        "\n",
        "  def model_section(self):\n",
        "    model_block = [\n",
        "        wr.H1(text = \"Model information\"),\n",
        "        wr.P(\"The following section shows information about the model. The table below contains information about the models' layers.\"),\n",
        "        wr.UnorderedList(items=self.model_info),\n",
        "        wr.PanelGrid(\n",
        "          runsets=[\n",
        "            wr.Runset(self.entity, self.project),\n",
        "          ],\n",
        "          panels = [\n",
        "              wr.WeavePanelSummaryTable(\"layer_table\")\n",
        "          ]\n",
        "        ),\n",
        "        wr.HorizontalRule()\n",
        "    ]\n",
        "    return model_block\n",
        "\n",
        "\n",
        "  # function to log sequence length table to wandb\n",
        "  def log_sequence_length_table(self, data: pd.DataFrame, seq_col:str = \"modified_sequence\"):\n",
        "    name_hist = \"counts_hist\"\n",
        "    counts = self.count_seq_length(data, seq_col)\n",
        "    # convert to df for easier handling\n",
        "    counts_df = counts.to_frame()\n",
        "    table = wandb.Table(dataframe = counts_df)\n",
        "    # log to wandb\n",
        "    hist = wandb.plot_table(\n",
        "      vega_spec_name=\"master_praktikum/hist_pep_len\",\n",
        "      data_table = table,\n",
        "      fields = {\"value\" : seq_col}\n",
        "    )\n",
        "    wandb.log({name_hist: hist})\n",
        "    name_hist_table = name_hist + \"_table\"\n",
        "    return name_hist_table\n",
        "\n",
        "  # function to count sequence length\n",
        "  def count_seq_length(self, data: pd.DataFrame, seq_col: str) -> pd.Series:\n",
        "      pattern = re.compile(r\"\\[UNIMOD:.*\\]\", re.IGNORECASE)\n",
        "      data[seq_col].replace(pattern, \"\", inplace= True)\n",
        "      return data[seq_col].str.len()\n",
        "\n",
        "  # function to log retention time table to wandb\n",
        "  def log_rt_table(self, data: pd.DataFrame, rt_col:str = \"indexed_retention_time\"):\n",
        "    name_hist = \"rt_hist\"\n",
        "    rt = data.loc[:,rt_col]\n",
        "    # convert to df for easier handling\n",
        "    rt_df = rt.to_frame()\n",
        "    table = wandb.Table(dataframe = rt_df)\n",
        "    # log to wandb\n",
        "    hist = wandb.plot_table(\n",
        "      vega_spec_name=\"master_praktikum/hist_ret_time\",\n",
        "      data_table = table,\n",
        "      fields = {\"value\" : rt_col}\n",
        "    )\n",
        "    wandb.log({name_hist: hist})\n",
        "    name_hist_table = name_hist + \"_table\"\n",
        "    return name_hist_table\n",
        "\n",
        "  def log_data(self):\n",
        "\n",
        "    # check if datasource is a string\n",
        "    if isinstance(self.dataset.data_source, str):\n",
        "      # read corresponding file\n",
        "      file_extension = self.dataset.data_source.split(\".\")[-1]\n",
        "      match file_extension:\n",
        "        case \"csv\":\n",
        "          data = pd.read_csv(self.dataset.data_source)\n",
        "        case \"json\":\n",
        "          data = pd.read_json(self.dataset.data_source)\n",
        "        case \"parquet\":\n",
        "          data = pd.read_parquet(self.dataset.data_source, engine='fastparquet')\n",
        "      self.table_key_len = self.log_sequence_length_table(data, self.dataset.sequence_col)\n",
        "      self.table_key_rt = self.log_rt_table(data, self.dataset.target_col)\n",
        "\n",
        "    # check if datasource is a tuple of two ndarrays or two lists\n",
        "    if isinstance(self.dataset.data_source, tuple) and all(isinstance(item, (np.ndarray, list)) for item in self.dataset.data_source) and len(self.dataset.data_source) == 2:\n",
        "      data = pd.DataFrame({self.dataset.sequence_col: self.dataset.data_source[0], self.dataset.target_col: self.dataset.data_source[1]})\n",
        "      self.table_key_len = self.log_sequence_length_table(data, self.dataset.sequence_col)\n",
        "      self.table_key_rt = self.log_rt_table(data, self.dataset.target_col)\n",
        "\n",
        "    # check if datasource is a single ndarray or list\n",
        "    # does not work? maybe error in RetentionTimeDataset\n",
        "    if isinstance(self.dataset.data_source, (np.ndarray, list)):\n",
        "      data = pd.DataFrame({self.dataset.sequence_col: self.dataset.data_source})\n",
        "      self.table_key_len = self.log_sequence_length_table(data, self.dataset.sequence_col)\n",
        "\n",
        "  def log_model_data(self, model):\n",
        "    from contextlib import redirect_stdout\n",
        "    # save modelsummary to txt\n",
        "    with open('modelsummary.txt', 'w') as f:\n",
        "        with redirect_stdout(f):\n",
        "            model.summary()\n",
        "    # read txt line by line\n",
        "    with open('modelsummary.txt') as f:\n",
        "        lines = [line.rstrip() for line in f]\n",
        "\n",
        "    # remove formatting lines\n",
        "    strings_to_remove = [\"____\", \"====\"]\n",
        "    cleaned_list = [item for item in lines if not any(string in item for string in strings_to_remove)]\n",
        "\n",
        "    # split into words by splitting if there are more than two whitespaces\n",
        "    words = []\n",
        "    for line in cleaned_list:\n",
        "      words.append(re.split(r\"\\s{2,}\", line))\n",
        "\n",
        "    # remove lines that contain less than 3 characters\n",
        "    filtered_list_of_lists = [sublist for sublist in words if all(len(item) > 3 for item in sublist)]\n",
        "\n",
        "    # extract layer info and model info\n",
        "    layer_info = [sublist for sublist in filtered_list_of_lists if len(sublist) > 2]\n",
        "    model_info = [sublist for sublist in filtered_list_of_lists if len(sublist) < 2]\n",
        "\n",
        "    # flatten model_info and filter entries with length smaller than 5\n",
        "    model_info_flat = [item for sublist in model_info for item in sublist]\n",
        "    model_info_flat_filtered = [item for item in model_info_flat if len(item) >= 5]\n",
        "\n",
        "    # create layer_info_df\n",
        "    column_names = layer_info[0]\n",
        "    layer_info_df = pd.DataFrame(layer_info[1:], columns = column_names)\n",
        "\n",
        "    # log layer_table to wandb\n",
        "    layer_table = wandb.Table(dataframe = layer_info_df)\n",
        "    wandb.log({\"layer_table\": layer_table})\n",
        "\n",
        "    # attach model_info to object\n",
        "    self.model_info = model_info_flat_filtered\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Weights & Biases\n"
      ],
      "metadata": {
        "id": "gia0RFRSwyiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create config\n",
        "config = {\n",
        "  \"seq_length\" : 30,\n",
        "  \"batch_size\" : 64,\n",
        "  \"val_ratio\" : 0.2,\n",
        "  \"lr\" : 0.001,\n",
        "  \"optimizer\" : \"Adam\",\n",
        "  \"loss\" : \"mse\"\n",
        "}\n",
        "\n",
        "# Initialize WANDB\n",
        "PROJECT = 'Demo_RetentionTimeReport'\n",
        "RUN = \"run_2\"\n",
        "wandb.init(project = PROJECT, name = RUN, config = config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "RHJW1mfew4B2",
        "outputId": "d07e4939-43d4-4832-e7cd-ac5fe0db02dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230829_114743-k2uey421</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/master_praktikum/Demo_RetentionTimeReport/runs/k2uey421' target=\"_blank\">run_2</a></strong> to <a href='https://wandb.ai/master_praktikum/Demo_RetentionTimeReport' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/master_praktikum/Demo_RetentionTimeReport' target=\"_blank\">https://wandb.ai/master_praktikum/Demo_RetentionTimeReport</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/master_praktikum/Demo_RetentionTimeReport/runs/k2uey421' target=\"_blank\">https://wandb.ai/master_praktikum/Demo_RetentionTimeReport/runs/k2uey421</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/master_praktikum/Demo_RetentionTimeReport/runs/k2uey421?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bc357f73910>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "n4bl32mwwlHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load small train dataset\n",
        "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix-resources/main/example_datasets/RetentionTime/proteomeTools_train_val.csv'\n",
        "\n",
        "# create dataset\n",
        "rtdata = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
        "                              seq_length = config[\"seq_length\"],\n",
        "                              batch_size = config[\"batch_size\"],\n",
        "                              val_ratio = config[\"val_ratio\"],\n",
        "                              test = False)"
      ],
      "metadata": {
        "id": "At1-MajHwG5e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize report"
      ],
      "metadata": {
        "id": "-X-RIIVY3O2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a report\n",
        "report = Report(project = \"Demo_RetentionTimeReport\",\n",
        "                title = \"Comparison of different optimizers\",\n",
        "                description = \"Comparison of two optimizers Adam and RMSprop\",\n",
        "                dataset = rtdata)"
      ],
      "metadata": {
        "id": "_Lv_t6Dv3Q6s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log data to Weights & Biases"
      ],
      "metadata": {
        "id": "o33NlIw3xJs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report.log_data()"
      ],
      "metadata": {
        "id": "FE8OvEml3CBU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "dFDNpH5S4HG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create retention time predictor\n",
        "model = RetentionTimePredictor(seq_length = config[\"seq_length\"])\n",
        "\n",
        "# create the optimizer object\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = config[\"lr\"])\n",
        "\n",
        "# compile the model with the optimizer and the metrics we want to use\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = config[\"loss\"],\n",
        "              metrics=['mean_absolute_error', TimeDeltaMetric()])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(rtdata.train_data,\n",
        "                    validation_data=rtdata.val_data,\n",
        "                    epochs=15,\n",
        "                    callbacks=[WandbMetricsLogger(log_freq = \"batch\")])\n",
        "\n",
        "# log model data to wandb\n",
        "report.log_model_data(model)\n",
        "\n",
        "# finish wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "UITv7MsK4I9j",
        "outputId": "74497bd7-093d-4c23-9709-94485cd370f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "424/424 [==============================] - 10s 17ms/step - loss: 633.3423 - mean_absolute_error: 17.4534 - timedelta: 18.3438 - val_loss: 170.6511 - val_mean_absolute_error: 9.6868 - val_timedelta: 8.3785\n",
            "Epoch 2/15\n",
            "424/424 [==============================] - 8s 19ms/step - loss: 149.0896 - mean_absolute_error: 8.9192 - timedelta: 9.5440 - val_loss: 139.8039 - val_mean_absolute_error: 8.4125 - val_timedelta: 8.0864\n",
            "Epoch 3/15\n",
            "424/424 [==============================] - 7s 16ms/step - loss: 119.4671 - mean_absolute_error: 7.8562 - timedelta: 8.4137 - val_loss: 106.0850 - val_mean_absolute_error: 7.2783 - val_timedelta: 7.3686\n",
            "Epoch 4/15\n",
            "424/424 [==============================] - 8s 18ms/step - loss: 102.2478 - mean_absolute_error: 7.1894 - timedelta: 7.7221 - val_loss: 95.2410 - val_mean_absolute_error: 6.9196 - val_timedelta: 7.1215\n",
            "Epoch 5/15\n",
            "424/424 [==============================] - 8s 20ms/step - loss: 92.8689 - mean_absolute_error: 6.7905 - timedelta: 7.1860 - val_loss: 89.9214 - val_mean_absolute_error: 6.7175 - val_timedelta: 6.9067\n",
            "Epoch 6/15\n",
            "424/424 [==============================] - 7s 17ms/step - loss: 86.7466 - mean_absolute_error: 6.5255 - timedelta: 6.8437 - val_loss: 85.8638 - val_mean_absolute_error: 6.4876 - val_timedelta: 6.5823\n",
            "Epoch 7/15\n",
            "424/424 [==============================] - 8s 19ms/step - loss: 81.4163 - mean_absolute_error: 6.2852 - timedelta: 6.5421 - val_loss: 82.9555 - val_mean_absolute_error: 6.3764 - val_timedelta: 6.3476\n",
            "Epoch 8/15\n",
            "424/424 [==============================] - 9s 21ms/step - loss: 76.7226 - mean_absolute_error: 6.0611 - timedelta: 6.2928 - val_loss: 80.8027 - val_mean_absolute_error: 6.2866 - val_timedelta: 6.1714\n",
            "Epoch 9/15\n",
            "424/424 [==============================] - 7s 17ms/step - loss: 72.9391 - mean_absolute_error: 5.8800 - timedelta: 6.1349 - val_loss: 79.4348 - val_mean_absolute_error: 6.2381 - val_timedelta: 6.0991\n",
            "Epoch 10/15\n",
            "424/424 [==============================] - 7s 17ms/step - loss: 69.5024 - mean_absolute_error: 5.7098 - timedelta: 5.9938 - val_loss: 78.4198 - val_mean_absolute_error: 6.2235 - val_timedelta: 6.0876\n",
            "Epoch 11/15\n",
            "424/424 [==============================] - 9s 20ms/step - loss: 66.6255 - mean_absolute_error: 5.5649 - timedelta: 5.8588 - val_loss: 76.5955 - val_mean_absolute_error: 6.1272 - val_timedelta: 6.0135\n",
            "Epoch 12/15\n",
            "424/424 [==============================] - 10s 24ms/step - loss: 63.9644 - mean_absolute_error: 5.4336 - timedelta: 5.7470 - val_loss: 75.1434 - val_mean_absolute_error: 6.0415 - val_timedelta: 5.9589\n",
            "Epoch 13/15\n",
            "424/424 [==============================] - 7s 16ms/step - loss: 61.6027 - mean_absolute_error: 5.3192 - timedelta: 5.6643 - val_loss: 72.9531 - val_mean_absolute_error: 5.9136 - val_timedelta: 5.9047\n",
            "Epoch 14/15\n",
            "424/424 [==============================] - 6s 15ms/step - loss: 59.2637 - mean_absolute_error: 5.2101 - timedelta: 5.5648 - val_loss: 71.8459 - val_mean_absolute_error: 5.8432 - val_timedelta: 5.8723\n",
            "Epoch 15/15\n",
            "424/424 [==============================] - 9s 20ms/step - loss: 57.2860 - mean_absolute_error: 5.1234 - timedelta: 5.4591 - val_loss: 69.8947 - val_mean_absolute_error: 5.6697 - val_timedelta: 5.8821\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/mean_absolute_error</td><td>█▅▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/timedelta</td><td>█▅▄▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mean_absolute_error</td><td>█▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>epoch/timedelta</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▄▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_mean_absolute_error</td><td>█▆▄▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>epoch/val_timedelta</td><td>█▇▅▄▄▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/batch_step</td><td>6359</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>57.28604</td></tr><tr><td>batch/mean_absolute_error</td><td>5.12335</td></tr><tr><td>batch/timedelta</td><td>5.45911</td></tr><tr><td>epoch/epoch</td><td>14</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>57.28604</td></tr><tr><td>epoch/mean_absolute_error</td><td>5.12335</td></tr><tr><td>epoch/timedelta</td><td>5.45911</td></tr><tr><td>epoch/val_loss</td><td>69.89469</td></tr><tr><td>epoch/val_mean_absolute_error</td><td>5.66967</td></tr><tr><td>epoch/val_timedelta</td><td>5.88206</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run_2</strong> at: <a href='https://wandb.ai/master_praktikum/Demo_RetentionTimeReport/runs/k2uey421' target=\"_blank\">https://wandb.ai/master_praktikum/Demo_RetentionTimeReport/runs/k2uey421</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230829_114743-k2uey421/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Report"
      ],
      "metadata": {
        "id": "2t0tD68l4W_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report.create_report(add_data_section = True,\n",
        "                     add_train_section = True,\n",
        "                     add_val_section = True,\n",
        "                     add_train_val_section = True)"
      ],
      "metadata": {
        "id": "1hYO03Sy4Z0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d7bf28-b879-438e-937c-84965f460490"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Model: \"retention_time_predictor_1\"', 'Total params: 1,332,577', 'Trainable params: 1,332,577', 'Non-trainable params: 0']\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N3joiuC6cFrr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}