{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:36:07.899226618Z",
     "start_time": "2023-06-17T10:36:05.674499621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 12:36:06.015129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-17 12:36:06.117218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-17 12:36:06.117235: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-17 12:36:06.759012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-17 12:36:06.759077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-17 12:36:06.759084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['META_DATA', 'constants', 'data', 'eval', 'layers', 'losses', 'models', 'pipelines', 'reports', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix\n",
    "from dlomix import constants, data, eval, layers, models, pipelines, reports, utils\n",
    "print([x for x in dir(dlomix) if not x.startswith(\"_\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:36:36.784231163Z",
     "start_time": "2023-06-17T10:36:36.511507867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /home/andi/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016673642299974745, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2968ce8891b145efbad6e6a6e0bc18a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.15.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/master_praktikum/retention%20time%20sample%20run/runs/i2f1wrs9' target=\"_blank\">dulcet-music-3</a></strong> to <a href='https://wandb.ai/master_praktikum/retention%20time%20sample%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/master_praktikum/retention%20time%20sample%20run' target=\"_blank\">https://wandb.ai/master_praktikum/retention%20time%20sample%20run</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/master_praktikum/retention%20time%20sample%20run/runs/i2f1wrs9' target=\"_blank\">https://wandb.ai/master_praktikum/retention%20time%20sample%20run/runs/i2f1wrs9</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/master_praktikum/retention%20time%20sample%20run/runs/i2f1wrs9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f3c83058610>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter project name\n",
    "project_name = 'retention time sample run'\n",
    "wandb.init(project=project_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:38:07.833421790Z",
     "start_time": "2023-06-17T10:36:55.920138272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from dlomix.data import RetentionTimeDataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:01.658491060Z",
     "start_time": "2023-06-17T10:39:01.613916194Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andi/miniconda3/envs/mp/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 12:39:06.849479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-17 12:39:06.855666: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-17 12:39:06.859656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (andi-Vostro-7590): /proc/driver/nvidia/version does not exist\n",
      "2023-06-17 12:39:06.877803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATAPATH = 'https://raw.githubusercontent.com/wilhelm-lab/dlomix/develop/example_dataset/proteomTools_train_val.csv'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "rtdata = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                              seq_length=30, batch_size=BATCH_SIZE, val_ratio=0.2, test=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:07.429497746Z",
     "start_time": "2023-06-17T10:39:06.271527943Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "('Training examples', 27136)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"Training examples\", BATCH_SIZE * len(rtdata.train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:18.463585692Z",
     "start_time": "2023-06-17T10:39:18.418858794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "('Validation examples', 6784)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Validation examples\", BATCH_SIZE * len(rtdata.val_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:29.031729986Z",
     "start_time": "2023-06-17T10:39:29.026401637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "\n",
    "config.seq_length = 30\n",
    "config.batch_size = BATCH_SIZE\n",
    "config.val_ratio = 0.2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:49.188591340Z",
     "start_time": "2023-06-17T10:39:49.184394101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from dlomix.models import RetentionTimePredictor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:51.297870391Z",
     "start_time": "2023-06-17T10:39:51.292871609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from dlomix.models import RetentionTimePredictor\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:39:56.710903007Z",
     "start_time": "2023-06-17T10:39:56.687109600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "#imports\n",
    "\n",
    "from dlomix.eval import TimeDeltaMetric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:41:04.769665144Z",
     "start_time": "2023-06-17T10:41:04.764398838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = RetentionTimePredictor(seq_length=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:41:05.920948144Z",
     "start_time": "2023-06-17T10:41:05.897175021Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# compile the model  with the optimizer and the metrics we want to use, we can add our custom timedelta metric\n",
    "\n",
    "# you can also import tensorflow and build your custom optimizer object and pass it\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mean_absolute_error', TimeDeltaMetric()])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:41:06.282806737Z",
     "start_time": "2023-06-17T10:41:06.255449501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# add more parameters to config as per need\n",
    "\n",
    "config.lr = 0.0001\n",
    "config.optimizer = \"adam\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:41:16.169387053Z",
     "start_time": "2023-06-17T10:41:16.135924831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# add more parameters to config as per need\n",
    "\n",
    "config.lr = 0.0001\n",
    "config.optimizer = \"adam\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:41:25.927409703Z",
     "start_time": "2023-06-17T10:41:25.906587177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "424/424 [==============================] - ETA: 0s - loss: 703.7172 - mean_absolute_error: 18.8156 - timedelta: 19.5490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (/home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 22s 49ms/step - loss: 703.7172 - mean_absolute_error: 18.8156 - timedelta: 19.5490 - val_loss: 193.1615 - val_mean_absolute_error: 10.1671 - val_timedelta: 9.0717\n",
      "Epoch 2/5\n",
      "423/424 [============================>.] - ETA: 0s - loss: 151.9522 - mean_absolute_error: 9.0092 - timedelta: 9.6870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (/home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 17s 39ms/step - loss: 151.8955 - mean_absolute_error: 9.0076 - timedelta: 9.6676 - val_loss: 128.2625 - val_mean_absolute_error: 8.1023 - val_timedelta: 7.8995\n",
      "Epoch 3/5\n",
      "424/424 [==============================] - ETA: 0s - loss: 115.5087 - mean_absolute_error: 7.7296 - timedelta: 8.3200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (/home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 17s 41ms/step - loss: 115.5087 - mean_absolute_error: 7.7296 - timedelta: 8.3200 - val_loss: 102.7056 - val_mean_absolute_error: 7.2408 - val_timedelta: 7.4082\n",
      "Epoch 4/5\n",
      "423/424 [============================>.] - ETA: 0s - loss: 98.0979 - mean_absolute_error: 7.0253 - timedelta: 7.3305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (/home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 17s 40ms/step - loss: 98.0784 - mean_absolute_error: 7.0257 - timedelta: 7.3179 - val_loss: 93.4125 - val_mean_absolute_error: 6.9131 - val_timedelta: 6.8360\n",
      "Epoch 5/5\n",
      "423/424 [============================>.] - ETA: 0s - loss: 89.5386 - mean_absolute_error: 6.6488 - timedelta: 6.8344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Can't save model in the h5py format. The model will be saved as as an W&B Artifact in the 'tf' format.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best/assets\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Adding directory to artifact (/home/andi/PycharmProjects/pythonProject2/wandb/run-20230617_123802-i2f1wrs9/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 17s 40ms/step - loss: 89.5166 - mean_absolute_error: 6.6489 - timedelta: 6.8220 - val_loss: 88.0817 - val_mean_absolute_error: 6.6841 - val_timedelta: 6.4486\n"
     ]
    }
   ],
   "source": [
    "# here we pass the WandbCallback to model.fit\n",
    "\n",
    "history = model.fit(rtdata.train_data,\n",
    "                    validation_data=rtdata.val_data,\n",
    "                    epochs=5, callbacks=[WandbCallback()] )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T10:43:01.983750542Z",
     "start_time": "2023-06-17T10:41:31.803406811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
